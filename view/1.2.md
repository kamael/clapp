## 1.2 有监督学习

![y \in \{1, ..., C\}](http://latex.codecogs.com/gif.latex?y%20%5Cin%20%5C%7B1%2C%20...%2C%20C%5C%7D)

+ C = 2，则为二元分类(binary classification)
+ C > 2，则为多元分类(multiclass classification)。如果这些类的标签不是互斥的，则称之为多标签分类(multi-label classification)，一般称之为多输出模型(multiple output model)。一般地，当我们讨论分类问题的时候，一般只有一个输出，而多元之间是互斥的

这类问题的正式称谓为近似方程(function approximation)。我们假想存在一个方程 y = f(x) 。现在通过训练，我们得到一个近似方程 ![\hat{y} = \hat{f}(x)](http://latex.codecogs.com/gif.latex?%5Chat%7By%7D%20%3D%20%5Chat%7Bf%7D%28x%29) 。对于一个未知的输入，我们可以预测到他的近似输出(泛化(generalization))

## 1.2.1.1 例子

在这个例子中，我们可以通过猜测得到一些结果。但是这些结果是否正确是未知的。

## 1.2.1.2 概率预测的需要

我们用这种方式表示概率分布：![p(y|x, D, M)](http://latex.codecogs.com/gif.latex?p%28y%7Cx%2C%20D%2C%20M%29)，对于模型M，在训练集![D](http://latex.codecogs.com/gif.latex?D)上，目标为![y](http://latex.codecogs.com/gif.latex?y)时的概率。

![\hat{y} = \hat{f}(x) =\begin{gather} &C\\ & argmax\\ & c=1\end{gather}\ p(y=c|x, D, M)](http://latex.codecogs.com/gif.latex?%5Chat%7By%7D%20%3D%20%5Chat%7Bf%7D%28x%29%20%3D%5Cbegin%7Bgather%7D%20%26C%5C%5C%20%26%20argmax%5C%5C%20%26%20c%3D1%5Cend%7Bgather%7D%5C%20p%28y%3Dc%7Cx%2C%20D%2C%20M%29) 

这里 ![\hat{y}](http://latex.codecogs.com/gif.latex?%5Chat%7By%7D) 被称为最大后验估计(MAP estimate (MAP stands for maximum a posteriori))。通过最大后验估计我们可以得到在该条件下，![y](http://latex.codecogs.com/gif.latex?y)最可能的值。

概率密度函数(probability density function, as pdf)

