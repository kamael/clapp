## 离散数据的生成模型(Generative models for discrete data)

### 3.2 Bayesian concept learning

当我们看到$\{16,8,2,64\}$时，为什么会更倾向于认为其内在规律为“2的n次方”，而非“偶数”呢？

#### 3.2.1 似然

一种直观的解释是，我们力图避免过度巧合。

$$p(D|h) =  \left[ \frac{1}{size(h)} \right]^N = \left[\frac{1}{|h|} \right]^N$$

这个公式称为尺度原则

例如，令$D=\{16\}$，那么$p(D|h_{two})= 1/6$，因为只有100以内，只有6个数为2的次方。但是$p(D|h_{even})=1/50$，因为100以内有50个偶数。当数字变成上面的四个的时候，$p(D|h_{two})= (1/6)^4=7.7 \times 10^{-4}, p(D|h_{even} = (1/50)^4) = 1.6 \times 10^{-7}$，后者比前者小太多，于是倾向于认为规律是前者。

####  3.2.2 先验

然而，“2的次方除去32”这个规律的特殊性更强，为什么不是它呢？因为先验性的认为这个规律不自然。对于先验概念的选取，会对我们的学习产生直接的影响。通常，更为自然的规律设置更高的概率值，反之设置为低概率值。

#### 3.2.3 后验

$$p(h|D)
=\frac{p(D|h)p(h)}{\sum_{h^\prime \in H}p(D,h^\prime)}
=\frac{p(h)\Pi(D \in h)/|h|^N}{\sum_{h^\prime \in H}p(h^\prime)\Pi(D \in h^\prime)/|h^\prime|^N}$$

$\Pi(D \in h) = 1$当且仅当数据在假设h的范畴内。$H$为整个先验空间

当数据足够多的时候，数据将吞没先验，最大后验估计将趋向于最大似然估计(maximum likelihood estimate or MLE)

### 3.3 β二项模型(The beta-binomial model)

独立同分布(independent and identically distributed, as iid)





